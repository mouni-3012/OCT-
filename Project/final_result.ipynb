{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a41b7b1-5891-425f-9755-c5626532bf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\siva\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\siva\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\siva\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python opencv-contrib-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7d9a727-ff55-4687-a6cb-5116f313822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0eadac8-96b8-4762-9be5-71cba46602db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras imports\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "\n",
    "# other imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "993a766c-a847-4bb6-afb8-16c163c603f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\": \"vgg16\",\n",
    "    \"weights\": \"imagenet\",\n",
    "    \"classifier_path\": \"C:/Users/siva/Documents/OCT/OCT2017/classifier.pickle\",\n",
    "    \"img_p\": \"C:/Users/siva/Documents/OCT/OCT2017/val/DRUSEN/DRUSEN-9837663-1.jpeg\",\n",
    "    \"val\": \"C:/Users/siva/Documents/OCT/OCT2017/val/validation\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efb78e50-df6b-4dfc-87f7-a7899a991177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading the classifier...\n",
      "No predictions made or all predictions are incorrect.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 20480 features, but RandomForestClassifier is expecting 8192 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m flat \u001b[38;5;241m=\u001b[39m feature\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     66\u001b[0m flat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(flat, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m preds \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(flat)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, preds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    800\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    823\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    860\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    861\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    865\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 20480 features, but RandomForestClassifier is expecting 8192 features as input."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Load the base MobileNetV2 model for feature extraction\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "# Load the trained logistic regression classifier\n",
    "print(\"[INFO] Loading the classifier...\")\n",
    "classifier_path = \"C:/Users/siva/Documents/OCT/OCT2017/classifier.pickle\"\n",
    "with open(classifier_path, 'rb') as f:\n",
    "    classifier = pickle.load(f)\n",
    "\n",
    "# Define the image size for preprocessing\n",
    "image_size = (128, 128)\n",
    "\n",
    "# Define the path to the validation dataset folder\n",
    "validation_folder_path = 'C:/Users/siva/Documents/OCT/OCT2017/val'\n",
    "\n",
    "# Initialize variables for keeping track of the number of correct and incorrect predictions\n",
    "num_correct_predictions = 0\n",
    "num_incorrect_predictions = 0\n",
    "\n",
    "# Iterate through images in the validation folder\n",
    "for image_path in glob.glob(validation_folder_path + \"/*.JPEG\"):\n",
    "    img = image.load_img(image_path, target_size=image_size)  # Resize images to 128x128 pixels\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    # Predict features using the MobileNetV2 model\n",
    "    feature = model.predict(x)\n",
    "    \n",
    "    # Flatten the features\n",
    "    flat = feature.flatten()\n",
    "    flat = np.expand_dims(flat, axis=0)\n",
    "    \n",
    "    # Predict class label using the logistic regression classifier\n",
    "    prediction = classifier.predict(flat)[0]\n",
    "    \n",
    "    # Extract ground truth label from image file name\n",
    "    ground_truth_label = int(os.path.basename(image_path).split('_')[0][-1])\n",
    "    \n",
    "    # Update the count of correct and incorrect predictions\n",
    "    if prediction == ground_truth_label:\n",
    "        num_correct_predictions += 1\n",
    "    else:\n",
    "        num_incorrect_predictions += 1\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "total_predictions = num_correct_predictions + num_incorrect_predictions\n",
    "if total_predictions > 0:\n",
    "    accuracy = num_correct_predictions / total_predictions\n",
    "    print(f'Accuracy: {accuracy:.2%}')  # Format accuracy as a percentage\n",
    "else:\n",
    "    print('No predictions made or all predictions are incorrect.')\n",
    "\n",
    "# Read in a single image, preprocess it, and make predictions\n",
    "img_p = config[\"img_p\"]\n",
    "img = keras.utils.load_img(img_p, target_size=image_size)\n",
    "x = keras.utils.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "feature = model.predict(x)\n",
    "flat = feature.flatten()\n",
    "flat = np.expand_dims(flat, axis=0)\n",
    "preds = classifier.predict(flat)\n",
    "print(\"Predictions:\", preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57874651-b286-4c1d-8c12-311b08315b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_path = config['val']\n",
    "# load the trained logistic regression classifier\n",
    "print (\"[INFO] loading the classifier...\")\n",
    "classifier = pickle.load(open(config[\"classifier_path\"], 'rb'))\n",
    "\n",
    "# pretrained models needed to perform feature extraction on test data too!\n",
    "if config[\"model\"] == \"vgg16\":\n",
    "\tbase_model = VGG16(weights=config[\"weights\"])\n",
    "\tmodel = Model(base_model.input, base_model.get_layer('block5_pool').output)\n",
    "\timage_size = (128, 128)\n",
    "\n",
    "else:\n",
    "\tbase_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3002396c-e7a3-4afa-a986-bcb343670ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading the classifier...\n",
      "No predictions made or all predictions are incorrect.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Define the path to the validation dataset folder\n",
    "validation_folder_path = 'C:/Users/siva/Documents/OCT/OCT2017/val'\n",
    "\n",
    "# Initialize variables for keeping track of the number of correct and incorrect predictions\n",
    "num_correct_predictions = 0\n",
    "num_incorrect_predictions = 0\n",
    "\n",
    "# Load the trained logistic regression classifier\n",
    "print(\"[INFO] Loading the classifier...\")\n",
    "classifier_path = \"C:/Users/siva/Documents/OCT/OCT2017/classifier.pickle\"\n",
    "with open(classifier_path, 'rb') as f:\n",
    "    classifier = pickle.load(f)\n",
    "\n",
    "# Define the image size for preprocessing\n",
    "image_size = (128, 128)\n",
    "\n",
    "# Iterate through images in the validation folder\n",
    "for image_path in glob.glob(validation_folder_path + \"/*.JPEG\"):\n",
    "    img = image.load_img(image_path, target_size=image_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    # Predict features using the model (assuming 'model' is defined elsewhere)\n",
    "    feature = model_1.predict(x)\n",
    "    \n",
    "    # Flatten the features\n",
    "    flat = feature.flatten()\n",
    "    flat = np.expand_dims(flat, axis=0)\n",
    "    \n",
    "    # Predict class label using the logistic regression classifier\n",
    "    prediction = classifier.predict(flat)[0]\n",
    "    \n",
    "    # Extract ground truth label from image file name\n",
    "    ground_truth_label = int(os.path.basename(image_path).split('_')[0][-1])\n",
    "    \n",
    "    # Update the count of correct and incorrect predictions\n",
    "    if prediction == ground_truth_label:\n",
    "        num_correct_predictions += 1\n",
    "    else:\n",
    "        num_incorrect_predictions += 1\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "total_predictions = num_correct_predictions + num_incorrect_predictions\n",
    "if total_predictions > 0:\n",
    "    accuracy = num_correct_predictions / total_predictions\n",
    "    print(f'Accuracy: {accuracy:.2%}')  # Format accuracy as a percentage\n",
    "else:\n",
    "    print('No predictions made or all predictions are incorrect.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14882869-33c9-4a2c-a60f-7b4e03e110f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load and resize the image to 128x128\n",
    "img = image.load_img(img_p, target_size=(128, 128))\n",
    "\n",
    "# Convert the image object to a NumPy array\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# Expand dimensions and preprocess the input\n",
    "x = np.expand_dims(x, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18dbdc09-33fb-4ef7-a5b4-e38d9c62000d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Invalid index: 485\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the model\n",
    "preds = model.predict(x)\n",
    "\n",
    "# Determine the predicted label\n",
    "index = np.argmax(feature[0])  # Find the index of the maximum value in the prediction\n",
    "\n",
    "# Check if the index is within the valid range\n",
    "if index < len(label_check1):\n",
    "    label = label_check1[index]    # Get the corresponding label from the label_check1 array\n",
    "    print(\"Predicted label:\", label)\n",
    "else:\n",
    "    print(\"Invalid index:\", index)\n",
    "    # Handle the case where the index is out of range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b11a871c-54d9-4cc9-a17d-aa4670c9d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_check1 = ['normal','cnv', 'dme', 'drusen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3166d58e-d804-4a82-851a-61c236518d22",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m label_check1[feature[\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "label_check1[feature[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717bc2cc-e0d5-408f-886e-b2183b8b0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "if (preds != 0).any():\n",
    "    import cv2\n",
    "\n",
    "    # Load the retinal OCT scan image\n",
    "    img = cv2.imread(img_p)\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    height, width, channels = img.shape\n",
    "\n",
    "    # Define the region of interest (ROI) as the central 50% of the image\n",
    "    roi_x = int(width * 0.25)\n",
    "    roi_y = int(height * 0.25)\n",
    "    roi_width = int(width * 0.5)\n",
    "    roi_height = int(height * 0.5)\n",
    "\n",
    "    # Crop the image to the ROI\n",
    "    img_roi = img[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width]\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding to create a binary image with bright or dark spots\n",
    "    _, binary = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours of the binary image\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the contour with the largest area\n",
    "    largest_contour = None\n",
    "    largest_contour_area = 0\n",
    "    for contour in contours:\n",
    "        contour_area = cv2.contourArea(contour)\n",
    "        if contour_area > largest_contour_area:\n",
    "            largest_contour = contour\n",
    "            largest_contour_area = contour_area\n",
    "\n",
    "    # Draw the largest contour on the original image with green color and thickness of 2\n",
    "    if largest_contour is not None:\n",
    "        # Shift the contour to account for the ROI crop\n",
    "        largest_contour[:, :, 0] += roi_x\n",
    "        largest_contour[:, :, 1] += roi_y\n",
    "    \n",
    "        cv2.drawContours(img, [largest_contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the resulting image\n",
    "    cv2.imshow('Retinal OCT Scan with Highlighted Pathology', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "else:\n",
    "    img = cv2.imread(img_p)\n",
    "    cv2.imshow('Retinal OCT Scan with Highlighted Pathology', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d913ca8-2e64-4e7c-b638-e9dd48b5da8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c526ca-0cb4-498b-8c86-ff2390cf0c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d40f1-7000-4cfa-9570-e19a50235461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a261ae6-32d2-4b24-83a7-a48b62df9b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c710d-6d6c-4d31-b060-fddea1db03b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff185b-076f-4620-8a7f-455b8014428a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
